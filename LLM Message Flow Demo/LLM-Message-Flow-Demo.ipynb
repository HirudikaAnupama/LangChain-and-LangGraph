{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4977f9ab",
   "metadata": {},
   "source": [
    "### Load Environment & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e0c99a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env and import libs\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pydantic import BaseModel, UUID4, Field\n",
    "import uuid\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, AIMessageChunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beb0751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file into environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e96a85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded: True\n"
     ]
    }
   ],
   "source": [
    "print(\"API key loaded:\", bool(api_key))  # Test: Should print True if key loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38efea3f",
   "metadata": {},
   "source": [
    "### Define Pydantic Message Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ead71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatMessage(BaseModel):\n",
    "    id: UUID4 = Field(default_factory=uuid.uuid4)\n",
    "    sender: str  # 'human' or 'ai'\n",
    "    message: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d3315b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=UUID('630fd821-f94a-4556-952d-316c4732496e') sender='human' message='Hello!'\n"
     ]
    }
   ],
   "source": [
    "# Test creating a valid message\n",
    "msg = ChatMessage(sender=\"human\", message=\"Hello!\")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f57539",
   "metadata": {},
   "source": [
    "### Initialize LangChain Chat Model using init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "209d1d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = init_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_provider=\"openai\",\n",
    "    openai_api_key=api_key,\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b11869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has invoke method? True\n"
     ]
    }
   ],
   "source": [
    "# Test: Check if chat_model supports invoke()\n",
    "print(\"Has invoke method?\", hasattr(chat_model, \"invoke\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810c2d4",
   "metadata": {},
   "source": [
    "### Convert Pydantic Messages to LangChain HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59706772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lc_messages(messages: list[ChatMessage]):\n",
    "    return [HumanMessage(content=msg.message) for msg in messages if msg.sender == \"human\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96086d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hello there!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Test:\n",
    "input_msgs = [\n",
    "    ChatMessage(sender=\"human\", message=\"Hello there!\"),\n",
    "    ChatMessage(sender=\"ai\", message=\"Hi! How can I help?\")\n",
    "]\n",
    "\n",
    "lc_msgs = convert_to_lc_messages(input_msgs)\n",
    "print(lc_msgs)  # Should print list with only human messages as HumanMessage objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b2a01",
   "metadata": {},
   "source": [
    "### Chat function â€” send messages and get AI reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d5078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AI] LangChain is a framework designed to help developers build applications that use language models, like those from OpenAI. It provides tools and components to make it easier to integrate these models into various applications, allowing developers to create chatbots, question-answering systems, and other language-based functionalities. Essentially, LangChain simplifies the process of working with language models by offering pre-built modules and workflows.\n"
     ]
    }
   ],
   "source": [
    "def chat_with_model(messages: list[ChatMessage], chat_model):\n",
    "    lc_messages = convert_to_lc_messages(messages)\n",
    "    response = chat_model.invoke(lc_messages)\n",
    "    return ChatMessage(sender=\"ai\", message=response.content)\n",
    "\n",
    "# Test chat function\n",
    "history = [\n",
    "    ChatMessage(sender=\"human\", message=\"What is LangChain?\"),\n",
    "    ChatMessage(sender=\"human\", message=\"Explain simply.\")\n",
    "]\n",
    "\n",
    "ai_resp = chat_with_model(history, chat_model)\n",
    "print(\"[AI]\", ai_resp.message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cba73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_chat_env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
