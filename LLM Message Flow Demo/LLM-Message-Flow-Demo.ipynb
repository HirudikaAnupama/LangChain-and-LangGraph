{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "867cc906",
   "metadata": {},
   "source": [
    "### Define Structured Message Format using Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e81dbd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseModel: Base class to define structured, validated models.\n",
    "# UUID4: Unique ID per message\n",
    "from pydantic import BaseModel, UUID4, Field\n",
    "import uuid  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3f9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatMessage(BaseModel):\n",
    "    id: UUID4 = Field(default_factory=uuid.uuid4)\n",
    "    sender: str  # e.g., 'human' or 'ai'\n",
    "    message: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35045c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=UUID('61d7bd7a-f9dc-4f01-8f9c-0f92b052aae7') sender='human' message='Hello, how are you?'\n"
     ]
    }
   ],
   "source": [
    "test_msg = ChatMessage(sender='human', message='Hello, how are you?')\n",
    "print(test_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16248c53",
   "metadata": {},
   "source": [
    "### Convert to LangChain-Compatible Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd34bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LangChain expects HumanMessage objects instead of raw strings for LLM inputs\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865d7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lc_message(messages: list[ChatMessage]):\n",
    "    return[HumanMessage(content=msg.message) for msg in messages if msg.sender == 'human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e0772f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello, how are you?' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "lc_test = convert_to_lc_message([test_msg])\n",
    "print(lc_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44813748",
   "metadata": {},
   "source": [
    "### Wrap a LangChain-Compatible Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5910d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizes .invoke() so your app can work with any LLM backend (OpenAI, HuggingFace, etc.).\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d76b0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "\n",
    "chat_llm  = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # or \"gpt-4\", \"gpt-3.5-turbo\"\n",
    "    temperature=0.3       # Optional: controls creativity\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_chat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
